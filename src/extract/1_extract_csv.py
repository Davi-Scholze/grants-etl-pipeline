import os
import pandas as pd
import logging
from dotenv import load_dotenv

# ================= CONFIGURAÃ‡Ã•ES =================

load_dotenv()

DIR_DOWNLOADS = os.getenv("DIR_DOWNLOADS")
DIR_STAGING = os.getenv("DIR_STAGING")

if not DIR_DOWNLOADS or not DIR_STAGING:
    raise ValueError("ERRO: VariÃ¡veis DIR_DOWNLOADS ou DIR_STAGING nÃ£o definidas no arquivo .env")

ORIGEM_PASTA = DIR_DOWNLOADS
ARQUIVO_SAIDA = os.path.join(DIR_STAGING, "despesas_geral.csv")

# ================= MAPEAMENTOS =================

SIT_TERMO_MAP = {
    "57884": "6373",
    "63377": "6729",
    "66270": "6822",
    "67303": "6893",
    "67669": "6932",
    "71199": "26478",
    "74699": "26672"
}

MAPEAMENTO_DESPESAS = {
    "PESSOAL CIVIL": "PESSOAL",
    "OBRIGAÃ‡Ã•ES PATRONAIS": "ENCARGOS",
    "MATERIAIS DE CONSUMO": "MATERIAIS DE CONSUMO",
    "SERVIÃ‡OS DE TERCEIROS": "SERVIÃ‡OS DE TERCEIROS"
}

# Adicionado id_codigo_sit no inÃ­cio
COLUNAS_ORDEM = [
    "id_codigo_sit", "termo", "rubrica", "tipo_despesa", "cpf_cnpj", "favorecido",
    "tipo_doc_despesa", "descricao_despesa", "tipo_doc_pagamento",
    "data_pagamento", "data_debito_convenio", "valor", "id_termo_rubrica"
]

# ================= LOG =================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ================= FUNÃ‡Ã•ES AUXILIARES =================

def classificar_tipo(texto):
    texto = str(texto).upper()
    for chave, valor in MAPEAMENTO_DESPESAS.items():
        if chave in texto:
            return valor
    return "OUTROS"


def limpar_cpf(v):
    v = "".join(filter(str.isdigit, str(v)))
    if len(v) <= 11:
        return v.zfill(11)
    return v.zfill(14)


# ================= ETL =================

def executar_etl():
    logging.info("âž¡ï¸ INÃCIO ETAPA 1: ConsolidaÃ§Ã£o dos arquivos de despesas")

    dados_consolidados = []

    for sit, termo in SIT_TERMO_MAP.items():
        caminho_arquivo = os.path.join(ORIGEM_PASTA, f"Despesas_SIT_{sit}.xlsx")

        if not os.path.exists(caminho_arquivo):
            logging.warning(f"âš ï¸ Arquivo nÃ£o encontrado: {caminho_arquivo}")
            continue

        try:
            # LÃª tudo como string para evitar problemas de tipagem inicial
            df = pd.read_excel(caminho_arquivo, dtype=str)

            if "Data do Pagamento" not in df.columns:
                logging.warning(f"âš ï¸ Coluna 'Data do Pagamento' ausente em {caminho_arquivo}")
                continue

            # ================= TRATAMENTO DE DATAS =================

            df["data_pagto_temp"] = pd.to_datetime(
                df["Data do Pagamento"], dayfirst=True, errors="coerce"
            )

            col_debito = None
            if "Data DÃ©bito Conta ConvÃªvio" in df.columns:
                col_debito = "Data DÃ©bito Conta ConvÃªvio"
            elif "Data DÃ©bito Conta ConvÃªnio" in df.columns:
                col_debito = "Data DÃ©bito Conta ConvÃªnio"

            if col_debito:
                df["data_debito_temp"] = pd.to_datetime(
                    df[col_debito], dayfirst=True, errors="coerce"
                )
            else:
                df["data_debito_temp"] = pd.NaT

            df = df.dropna(subset=["data_pagto_temp"])

            # ================= CONSTRUÃ‡ÃƒO DO DATAFRAME LIMPO =================

            novo = pd.DataFrame(index=df.index)

            # --- NOVA COLUNA: CÃ“DIGO SIT ---
            # Verifica se a coluna "CÃ³digo" existe, senÃ£o preenche vazio ou trata erro
            if "CÃ³digo" in df.columns:
                novo["id_codigo_sit"] = df["CÃ³digo"].fillna("").str.strip()
            else:
                # Se for crÃ­tico nÃ£o ter o cÃ³digo, mude para raise ValueError
                novo["id_codigo_sit"] = "" 

            novo["termo"] = termo
            
            novo["rubrica"] = (
                df["Tipo de Despesa"]
                .str.extract(r"^([\d\.]+)", expand=False)
                .fillna("")
                .str.strip()
            )

            novo["tipo_despesa"] = df["Tipo de Despesa"].apply(classificar_tipo)
            novo["cpf_cnpj"] = df["CPF/CNPJ"].apply(limpar_cpf)
            novo["favorecido"] = df["Favorecido"].fillna("").str.strip()

            novo["tipo_doc_despesa"] = (
                df["Tipo Documento Despesa"].fillna("").str.strip()
                if "Tipo Documento Despesa" in df.columns else ""
            )

            novo["descricao_despesa"] = df["DescriÃ§Ã£o da Despesa"].fillna("").str.strip()

            novo["tipo_doc_pagamento"] = (
                df["Tipo Documento Pagamento"].fillna("").str.strip()
                if "Tipo Documento Pagamento" in df.columns else ""
            )

            novo["data_pagamento"] = df["data_pagto_temp"].dt.strftime("%Y-%m-%d")
            novo["data_debito_convenio"] = (
                df["data_debito_temp"].dt.strftime("%Y-%m-%d").fillna("")
            )

            novo["valor"] = pd.to_numeric(df["Valor"], errors="coerce").fillna(0.0)

            novo["id_termo_rubrica"] = novo["termo"] + "-" + novo["rubrica"]

            # ForÃ§a a ordem das colunas
            novo = novo[COLUNAS_ORDEM]

            dados_consolidados.append(novo)

            logging.info(f"âœ”ï¸ {caminho_arquivo} | {len(novo)} linhas processadas (Termo: {termo})")

        except Exception as e:
            logging.error(f"âŒ Erro ao processar {caminho_arquivo}: {e}")

    # ================= SAÃDA =================

    if dados_consolidados:
        df_final = pd.concat(dados_consolidados, ignore_index=True)

        os.makedirs(DIR_STAGING, exist_ok=True)

        df_final.to_csv(
            ARQUIVO_SAIDA,
            index=False,
            encoding="utf-8-sig",
            sep=","
        )

        logging.info(f"ðŸ’¾ Arquivo final gerado com {len(df_final)} linhas")
        logging.info(f"ðŸ“„ Caminho: {ARQUIVO_SAIDA}")

    else:
        logging.warning("âš ï¸ Nenhum dado vÃ¡lido encontrado para consolidaÃ§Ã£o")

if __name__ == "__main__":
    executar_etl()