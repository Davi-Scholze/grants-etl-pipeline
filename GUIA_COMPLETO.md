# ğŸ“š GUIA COMPLETO - GRANTS MANAGEMENT ETL PIPELINE

> **DocumentaÃ§Ã£o 100% DidÃ¡tica** - Entenda cada pasta, arquivo e processo do pipeline

---

## ğŸ“– Ãndice

1. [Arquitetura Geral](#arquitetura-geral)
2. [Estrutura de Pastas](#estrutura-de-pastas)
3. [Fluxo do Pipeline (3 Etapas)](#fluxo-do-pipeline)
4. [Como Usar](#como-usar)
5. [Docker & ProduÃ§Ã£o](#docker--produÃ§Ã£o)
6. [Troubleshooting](#troubleshooting)

---

## ğŸ—ï¸ Arquitetura Geral

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VOCÃŠ (UsuÃ¡rio)                        â”‚
â”‚              Click: python -m src.main                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     SINCRONIZAÃ‡ÃƒO AUTOMÃTICA (Downloads â†’ Raw)          â”‚
â”‚  Copia XLSX/CSV de C:\Users\...\Downloads para data/raw â”‚
â”‚              e deleta os originais                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETAPA 1: EXTRAÃ‡ÃƒO (Extract)                           â”‚
â”‚  LÃª arquivos e cria CSVs consolidados                   â”‚
â”‚  - LÃª: Despesas_SIT_*.xlsx (despesas)                   â”‚
â”‚  - LÃª: *.csv (resumos financeiros)                      â”‚
â”‚  - Gera: despesas_geral.csv                             â”‚
â”‚  - Gera: resumo_termos.csv + resumo_rubricas.csv        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETAPA 2: TRANSFORMAÃ‡ÃƒO (Transform)                    â”‚
â”‚  Compara dados com banco usando fingerprint (hash MD5)  â”‚
â”‚  - Detecta: INSERT (novo) / UPDATE (mudou)              â”‚
â”‚  - Gera: despesas_upload.csv (para INSERT/UPDATE)       â”‚
â”‚  - Gera: update_termos.csv (divergÃªncias)               â”‚
â”‚  - Gera: update_rubricas.csv (divergÃªncias)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PAUSA INTERATIVA â¸ï¸                                    â”‚
â”‚  Mostra dados que serÃ£o atualizados                     â”‚
â”‚  VocÃª digita SIM para continuar ou CANCELAR             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
            â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
            â”‚           â”‚
          [SIM]      [CANCELAR]
            â”‚           â”‚
            â–¼           â–¼
      ETAPA 3      FIM DO PIPELINE
            â”‚      (sem atualizar banco)
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ETAPA 3: CARGA (Load)                                 â”‚
â”‚  Escreve dados no SQL Server                            â”‚
â”‚  - INSERT: registros novos                              â”‚
â”‚  - UPDATE: registros alterados                          â”‚
â”‚  - Atualiza: termos (rendimento financeiro)             â”‚
â”‚  - Atualiza: rubricas (estornos)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         âœ… BANCO ATUALIZADO!
```

---

## ğŸ“ Estrutura de Pastas (ExplicaÃ§Ã£o Detalhada)

### Raiz do Projeto

```
Grants Management ETL Pipeline/
â”‚
â”œâ”€â”€ ğŸ”§ .env                    # CONFIGURAÃ‡ÃƒO SENSÃVEL (nÃ£o commitar!)
â”‚                              # ContÃ©m: caminhos, string de conexÃ£o SQL Server
â”‚
â”œâ”€â”€ ğŸ“ .env.template            # TEMPLATE do .env (seguro, para versionamento)
â”‚                              # Use como referÃªncia para criar .env
â”‚
â”œâ”€â”€ ğŸ“¦ requirements.txt         # DEPENDÃŠNCIAS PYTHON
â”‚                              # pandas, pyodbc, python-dotenv, etc
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile              # IMAGEM DOCKER (Linux com Python + ODBC)
â”‚
â”œâ”€â”€ ğŸ‹ docker-compose.yaml     # ORQUESTRAÃ‡ÃƒO Docker 
â”‚                              # SQL Server + ETL Pipeline in containers
â”‚
â”‚
â”œâ”€â”€ ğŸ“ data/                   # ğŸ­ DADOS (raw â†’ processed)
â”‚   â”œâ”€â”€ raw/                   # [ENTRADA] Arquivos recÃ©m-baixados
â”‚   â”‚   # VocÃª coloca aqui (ou main.py copia automaticamente)
â”‚   â”‚   # Espera: Despesas_SIT_57884.xlsx, resumo.csv, etc
â”‚   â”‚
â”‚   â””â”€â”€ processed/             # [PROCESSAMENTO] SaÃ­da do pipeline
â”‚       â”œâ”€â”€ despesas_geral.csv              â† ConsolidaÃ§Ã£o etapa 1
â”‚       â”œâ”€â”€ despesas_upload.csv             â† PendÃªncias etapa 2
â”‚       â”œâ”€â”€ despesas_upload.processado.csv  â† HistÃ³rico etapa 3
â”‚       â”œâ”€â”€ resumo_termos.csv               â† Termos extraÃ­dos
â”‚       â”œâ”€â”€ resumo_rubricas.csv             â† Rubricas extraÃ­das
â”‚       â”œâ”€â”€ update_termos.csv               â† DivergÃªncias encontradas
â”‚       â””â”€â”€ update_rubricas.csv             â† DivergÃªncias encontradas
â”‚
â”‚
â”œâ”€â”€ ğŸ“ database/               # ğŸ’¾ SQL SCRIPTS
â”‚   â”œâ”€â”€ ddl/                   # Schema (criaÃ§Ã£o de tabelas)
â”‚   â”‚   â”œâ”€â”€ estrutura_dbo_despesas.sql
â”‚   â”‚   â”œâ”€â”€ estrutura_dbo_favorecidos.sql
â”‚   â”‚   â”œâ”€â”€ estrutura_dbo_rubricas.sql
â”‚   â”‚   â”œâ”€â”€ estrutura_dbo_termos.sql
â”‚   â”‚   â””â”€â”€ estrutura_dbo_vagas_termos.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ dml/                   # Logic (updates/deletes)
â”‚   â”‚   â””â”€â”€ update_rules.sql
â”‚   â”‚
â”‚   â””â”€â”€ scripts_auxiliares/    # Ad-hoc scripts
â”‚       â””â”€â”€ *.sql              # ManutenÃ§Ã£o manual
â”‚
â”‚
â”œâ”€â”€ ğŸ“ docs/                   # ğŸ“š DOCUMENTAÃ‡ÃƒO
â”‚   â”œâ”€â”€ Estrutura de Pastas.txt
â”‚   â””â”€â”€ README.md              # (este arquivo)
â”‚
â”‚
â”œâ”€â”€ ğŸ“ logs/                   # ğŸ“‹ LOGS DE EXECUÃ‡ÃƒO
â”‚   # Criado automaticamente
â”‚   # ConteÃºdo: MainPipeline_20260209_143022.log, etc
â”‚
â”‚
â”œâ”€â”€ ğŸ“ reports/                # ğŸ“Š DASHBOARDS (Power BI)
â”‚   â”œâ”€â”€ Controle de RH Por ConvÃªnio.pbix
â”‚   â””â”€â”€ Grants_Dashboard.pbix
â”‚
â”‚
â””â”€â”€ ğŸ“ src/                    # ğŸ§  CÃ“DIGO-FONTE PYTHON
    â”‚
    â”œâ”€â”€ ğŸ main.py             # ORQUESTRADOR PRINCIPAL
    â”‚   # - ValidaÃ§Ã£o de .env
    â”‚   # - Sincroniza Downloads
    â”‚   # - Executa 3 etapas
    â”‚   # - Pausa para confirmaÃ§Ã£o
    â”‚
    â”œâ”€â”€ ğŸ“¥ extract/            # ETAPA 1: EXTRAÃ‡ÃƒO
    â”‚   â”œâ”€â”€ expenses.py        # NOVO: Wrapper funcional
    â”‚   â”‚   # Classes: ExpensesExtractor
    â”‚   â”‚   # MÃ©todos: run(), extrair_despesas_csv(), extrair_resumos()
    â”‚   â”‚
    â”‚   â”œâ”€â”€ 1_extract_csv.py   # Script original (referÃªncia)
    â”‚   â””â”€â”€ 1_extract_resumo.py # Script original (referÃªncia)
    â”‚
    â”œâ”€â”€ ğŸ”„ transform/          # ETAPA 2: TRANSFORMAÃ‡ÃƒO
    â”‚   â”œâ”€â”€ transformer.py     # NOVO: Wrapper funcional
    â”‚   â”‚   # Classes: ExpensesTransformer
    â”‚   â”‚   # MÃ©todos: run(), transformar_despesas(), validar_e_preparar()
    â”‚   â”‚
    â”‚   â”œâ”€â”€ 2_transform_compare.py  # Script original (referÃªncia)
    â”‚   â””â”€â”€ 2_validate.py           # Script original (referÃªncia)
    â”‚
    â”œâ”€â”€ ğŸ“¤ load/               # ETAPA 3: CARGA
    â”‚   â”œâ”€â”€ loader.py          # NOVO: Wrapper funcional
    â”‚   â”‚   # Classes: ExpensesLoader
    â”‚   â”‚   # MÃ©todos: run(), carregar_despesas(), atualizar_financeiro()
    â”‚   â”‚
    â”‚   â”œâ”€â”€ 3_load_sql.py      # Script original (referÃªncia)
    â”‚   â””â”€â”€ 3_update_sql.py    # Script original (referÃªncia)
    â”‚
    â””â”€â”€ ğŸ”§ utils/              # UTILITÃRIOS (importados por todos)
        â”œâ”€â”€ logger.py          # NOVO: Logging centralizado
        â”‚   # FunÃ§Ã£o: setup_logger()
        â”‚   # Cria logs em arquivos com timestamp
        â”‚
        â”œâ”€â”€ config.py          # NOVO: ConfiguraÃ§Ãµes centralizadas
        â”‚   # Classe: Config
        â”‚   # Atributos: DIR_DOWNLOADS, DIR_STAGING, CONN_STR, etc
        â”‚
        â”œâ”€â”€ database.py        # NOVO: Gerenciador de BD
        â”‚   # Classe: DatabaseManager
        â”‚   # MÃ©todos: get_connection(), execute_query(), execute_insert_update()
        â”‚
        â”œâ”€â”€ ingestor.py        # NOVO: FunÃ§Ãµes auxiliares
        â”‚   # FunÃ§Ãµes: classificar_tipo_despesa(), limpar_cpf_cnpj()
        â”‚   # FunÃ§Ãµes: copiar_downloads_para_raw() â† A FUNÃ‡ÃƒO NOVA!
        â”‚
        â””â”€â”€ README.md          # DocumentaÃ§Ã£o do mÃ³dulo src/
```

---

## â–¶ï¸ Fluxo do Pipeline (3 Etapas Detalhadas)

### ğŸŸ¢ ETAPA 1: EXTRAÃ‡ÃƒO (Extract)

**Objetivo:** Ler arquivos XLSX/CSV e consolidar em CSVs padronizados

**Entrada:**
- `data/raw/Despesas_SIT_57884.xlsx` (um para cada SIT)
- `data/raw/resumo*.csv` (archivos de resumo)

**Processo:**

```
1ï¸âƒ£ LÃª cada arquivo XLSX
   â”œâ”€ Converte para DataFrame
   â”œâ”€ Trata datas (dayfirst=True para brasileiro)
   â”œâ”€ Extrai rubrica do tipo de despesa
   â”œâ”€ Classifica tipo (PESSOAL, ENCARGOS, etc)
   â”œâ”€ Limpa CPF/CNPJ (remove formataÃ§Ã£o)
   â””â”€ Cria coluna id_termo_rubrica (chave composta)

2ï¸âƒ£ Consolida TODOS em um sÃ³ DataFrame
   â””â”€ Salva em: data/processed/despesas_geral.csv

3ï¸âƒ£ LÃª arquivos CSV de resumo
   â”œâ”€ Extrai SIT (nÃºmero identificador)
   â”œâ”€ Extrai rendimento financeiro
   â”œâ”€ Extrai rubricas com estornos
   â”œâ”€ Cria chave composta (SIT-RUBRICA)
   â””â”€ Salva em: data/processed/resumo_termos.csv
                data/processed/resumo_rubricas.csv
```

**SaÃ­da:**
```
âœ… despesas_geral.csv (150+ linhas, 13 colunas)
   Colunas: id_codigo_sit | termo | rubrica | tipo_despesa | cpf_cnpj | 
            favorecido | tipo_doc_despesa | descricao_despesa | 
            tipo_doc_pagamento | data_pagamento | data_debito_convenio | valor | id_termo_rubrica

âœ… resumo_termos.csv
   Colunas: nro_sit | rendimento_financeiro_total

âœ… resumo_rubricas.csv
   Colunas: nro_sit | rubrica | valor_estornado | id_termo_rubrica
```

---

### ğŸŸ¡ ETAPA 2: TRANSFORMAÃ‡ÃƒO (Transform)

**Objetivo:** Comparar dados com banco e identificar INSERT/UPDATE

**Processo:**

#### Fase A: ComparaÃ§Ã£o de Despesas

```
1ï¸âƒ£ Carrega despesas_geral.csv (do arquivo)

2ï¸âƒ£ Para cada registro, gera FINGERPRINT (hash MD5)
   Fingerprint = MD5(termo|rubrica|tipo|cpf|favorecido|...|valor)
   â†’ Serve para detectar QUALQUER mudanÃ§a

3ï¸âƒ£ Conecta ao SQL Server
   â”œâ”€ SELECT * FROM despesas WHERE id_codigo_sit NOT NULL
   â””â”€ Para cada um, gera fingerprint igual

4ï¸âƒ£ COMPARAÃ‡ÃƒO:
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ID nÃ£o existe no banco? â†’ INSERT        â”‚
   â”‚ ID existe E hash diferente? â†’ UPDATE    â”‚
   â”‚ ID existe E hash igual? â†’ IGNORAR       â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

5ï¸âƒ£ Salva resultado em: data/processed/despesas_upload.csv
   â””â”€ ContÃ©m coluna 'acao': INSERT ou UPDATE
```

#### Fase B: ValidaÃ§Ã£o de Termos e Rubricas

```
1ï¸âƒ£ CRIA MAPA SIT â†” ID_TERMO
   SELECT id_termo, nro_sit FROM termos
   â†’ Exemplo: {'57884': '6373', '63377': '6729', ...}

2ï¸âƒ£ COMPARA TERMOS
   â”œâ”€ LÃª resumo_termos.csv
   â”œâ”€ LÃª SELECT nro_sit, rendimento_financeiro_total FROM termos
   â”œâ”€ Se valor CSV â‰  valor banco (diferenÃ§a > R$ 0,01)
   â””â”€ Salva divergÃªncia em: data/processed/update_termos.csv

3ï¸âƒ£ COMPARA RUBRICAS
   â”œâ”€ LÃª resumo_rubricas.csv
   â”œâ”€ TRADUZ SIT para ID_TERMO usando MAPA
   â”œâ”€ Cria chave composta: "{id_termo}-{rubrica}"
   â”œâ”€ Se valor CSV â‰  valor banco (diferenÃ§a > R$ 0,01)
   â””â”€ Salva divergÃªncia em: data/processed/update_rubricas.csv
```

**SaÃ­da:**
```
âœ… despesas_upload.csv (com coluna 'acao')
   Exemplo:
   id_codigo_sit | termo | rubrica | ... | acao
   001           | 6373  | 3.3.90  | ... | INSERT
   002           | 6373  | 3.3.90  | ... | UPDATE

âœ… update_termos.csv (SOMENTE se hÃ¡ divergÃªncias)
   nro_sit | rendimento_financeiro_total_csv
   57884   | 1250.50

âœ… update_rubricas.csv (SOMENTE se hÃ¡ divergÃªncias)
   id_termo_rubrica | valor_estornado
   6373-3.3.90      | 500.25
```

---

### ğŸ”µ PAUSA INTERATIVA â¸ï¸

**Objetivo:** VocÃª CONFIRMAR antes de atualizar o banco

```
Pipeline mostra:
   ğŸ“Š DESPESAS A ATUALIZAR:
      â€¢ INSERT (novos): 10 registros
      â€¢ UPDATE (alterados): 2 registros
      â€¢ Total: 12 registros
      
      Amostra (primeiros registros):
         [INSERT] ID:001 | Termo:6373 | Valor:R$1500.50
         [INSERT] ID:002 | Termo:6373 | Valor:R$2000.00
         [UPDATE] ID:003 | Termo:6373 | Valor:R$3500.75
         ... +9 registros
   
   ğŸ’° TERMOS A ATUALIZAR: 2 registros
      SIT:57884 | Rendimento:R$5000.50
      SIT:63377 | Rendimento:R$3200.75
   
   ğŸ“‹ RUBRICAS A ATUALIZAR: 1 registros
      6373-3.3.90 | Estorno:R$500.25

â“ Os dados acima estÃ£o CORRETOS? Digite 'SIM' para continuar ou qualquer outra coisa para CANCELAR:
```

**Comportamento:**
- VocÃª digita `SIM` â†’ Continua para Etapa 3
- VocÃª digita qualquer outra coisa â†’ **CANCELA** (banco nÃ£o Ã© alterado)

---

### ğŸŸ£ ETAPA 3: CARGA (Load)

**Objetivo:** Escrever dados no SQL Server

#### Fase A: Carga de Despesas

```
1ï¸âƒ£ LÃª despesas_upload.csv

2ï¸âƒ£ Para cada registro:
   â”œâ”€ Se acao = 'INSERT':
   â”‚  â””â”€ INSERT INTO despesas (id_codigo_sit, termo, rubrica, ...)
   â”‚             VALUES (?, ?, ?, ...)
   â”‚
   â””â”€ Se acao = 'UPDATE':
      â””â”€ UPDATE despesas SET termo=?, rubrica=?, ...
                     WHERE id_codigo_sit = ?

3ï¸âƒ£ Conta: X INSERT, Y UPDATE

4ï¸âƒ£ Renomeia arquivo: despesas_upload.csv â†’ despesas_upload.processado.csv
   (HistÃ³rico de execuÃ§Ã£o)
```

#### Fase B: AtualizaÃ§Ã£o Financeira

```
1ï¸âƒ£ Se existe update_termos.csv:
   â””â”€ UPDATE termos SET rendimento_financeiro_total = ? 
                   WHERE nro_sit = ?

2ï¸âƒ£ Se existe update_rubricas.csv:
   â””â”€ UPDATE rubricas SET valor_estornado = ? 
                    WHERE id_termo_rubrica = ?

3ï¸âƒ£ Deleta arquivos (cleanup)
   â””â”€ Remove update_termos.csv e update_rubricas.csv
```

**SaÃ­da:**
```
ğŸš€ INSERT: 10 | UPDATE: 2
âœ… Banco atualizado com sucesso!
ğŸ’¾ HistÃ³rico: despesas_upload.processado.csv
```

---

## ğŸš€ Como Usar

### InstalaÃ§Ã£o

#### 1ï¸âƒ£ PrÃ©-requisitos

```bash
# Python 3.8+ jÃ¡ instalado
python --version

# Clone/baixe o projeto
cd "Grants Management ETL Pipeline"
```

#### 2ï¸âƒ£ Criar .env

```bash
# Copie o template
copy .env.template .env

# Edite com seus dados
# DIR_DOWNLOADS=...
# DIR_STAGING=...
# CONN_STR_SQLSERVER=...
```

#### 3ï¸âƒ£ Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### ExecuÃ§Ã£o

#### â–¶ï¸ Executar Pipeline Completo

```bash
python -m src.main
```

**O que acontece:**
```
1. Sincroniza Downloads â†’ data/raw
2. Extrai arquivos
3. Transforma e compara
4. **Pausa para confirmaÃ§Ã£o** â¸ï¸
5. Se SIM â†’ Carrega no banco
6. Logs salvos em logs/
```

#### â–¶ï¸ Executar Etapas Individualmente (Debugging)

```bash
# Apenas ExtraÃ§Ã£o
python -m src.extract.expenses

# Apenas TransformaÃ§Ã£o
python -m src.transform.transformer

# Apenas Carga
python -m src.load.loader
```

### ğŸ“‹ Verificar Logs

```bash
# Ver mais recente
cat logs/MainPipeline_*.log | tail -50

# Ou no VS Code
# Abra: logs/MainPipeline_20260209_143022.log
```

---

## ğŸ³ Docker & ProduÃ§Ã£o

### O que Ã© Docker?

Docker permite **empacotar a aplicaÃ§Ã£o + banco de dados** em containers isolados. VocÃª nÃ£o precisa instalar nada localmente!

### Arquivos Docker

#### `Dockerfile`
```dockerfile
# Imagem base: Python 3.11
FROM python:3.11-slim

# Instala ODBC driver (necessÃ¡rio para SQL Server)
RUN apt-get update && ...

# Copia a aplicaÃ§Ã£o
COPY . /app/

# Instala dependÃªncias
RUN pip install -r requirements.txt

# Comando ao iniciar
CMD ["python", "-m", "src.main"]
```

**O que faz:** Cria imagem Docker com Python + ODBC + cÃ³digo

#### `docker-compose.yaml`
```yaml
services:
  sqlserver:        # ServiÃ§o 1: SQL Server para dados
    image: mssql/server:2022-latest
    ports:
      - "1433:1433"
    environment:
      ACCEPT_EULA: "Y"
      MSSQL_SA_PASSWORD: "..."

  etl_pipeline:     # ServiÃ§o 2: AplicaÃ§Ã£o Python
    build: .
    depends_on:
      - sqlserver   # Aguarda SQL ficar pronto
    environment:
      CONN_STR_SQLSERVER: "Server=sqlserver,..."
```

**O que faz:** Orquestra SQL Server + ETL juntos

### Usar Docker

#### âœ… Build (cria imagem)

```bash
docker-compose build
```

#### âœ… Run (inicia containers)

```bash
# Both SQL Server + ETL
docker-compose up

# SÃ³ SQL Server (para desenvolvimento)
docker-compose up sqlserver

# SÃ³ ETL (depois que SQL estiver pronto)
docker-compose up etl_pipeline
```

#### âœ… Logs

```bash
docker-compose logs -f etl_pipeline
docker-compose logs -f sqlserver
```

#### âœ… Parar

```bash
docker-compose down
```

#### âœ… Deletar tudo (âš ï¸ CUIDADO - deleta dados!)

```bash
docker-compose down -v
```

---

## ğŸ” Troubleshooting

### âŒ "VariÃ¡veis de ambiente faltando"

**SoluÃ§Ã£o:**
```bash
# Verificar .env
cat .env

# Deve ter:
DIR_DOWNLOADS=C:\Users\usuario\Documents\...
DIR_STAGING=C:\Users\usuario\Documents\...
CONN_STR_SQLSERVER=Driver={...};Server=...;
```

### âŒ "Arquivo nÃ£o encontrado"

**SoluÃ§Ã£o:**
```bash
# Colocar arquivos em data/raw/ e rodar
python -m src.main

# Ou colocar em Downloads e deixar main.py copiar
# Main copia automaticamente!
```

### âŒ "Erro de conexÃ£o SQL Server"

**SoluÃ§Ã£o:**
```bash
# Verificar se SQL Server estÃ¡ rodando
# Se local: Services â†’ SQL Server Agent
# Se Docker: docker-compose up sqlserver

# Testar conexÃ£o:
python -c "
import pyodbc
conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};Server=localhost\SQLEXPRESS;Database=ETL_Convenios;Trusted_Connection=yes;')
print('âœ… Conectado!')
"
```

### âŒ "ODBC Driver nÃ£o encontrado"

**SoluÃ§Ã£o (Windows):**
```bash
# Instalar: https://docs.microsoft.com/sql/connect/odbc/download-odbc-driver-sql-server
# Depois: pip install pyodbc
```

**SoluÃ§Ã£o (Docker):**
```bash
# JÃ¡ estÃ¡ incluÃ­do no Dockerfile
# Usar docker-compose
```

### âŒ "Unicode / Encoding error"

**SoluÃ§Ã£o:**
```bash
# Etapa 1 trata automaticamente (Latin-1, UTF-8)
# Se ainda houver problema, verificar encoding dos CSVs
# Windows: Salvar como UTF-8 sem BOM
```

---

## ğŸ“Š Exemplo PrÃ¡tico Completo

### CenÃ¡rio: VocÃª tem 2 arquivos novos

```
C:\Users\usuario\Downloads\
â”œâ”€â”€ Despesas_SIT_57884.xlsx     â† Novo!
â””â”€â”€ resumo.csv                   â† Novo!
```

### Executa:

```bash
python -m src.main
```

### SaÃ­da Esperada:

```
ğŸ PIPELINE ETL - GRANTS MANAGEMENT - INICIANDO

ğŸ” Validando configuraÃ§Ãµes...
âœ… ConfiguraÃ§Ãµes OK

ğŸ“¥ Sincronizando arquivos de Downloads...
   ğŸ“¥ Movido: Despesas_SIT_57884.xlsx (original deletado)
   ğŸ“¥ Movido: resumo.csv (original deletado)
âœ… 2 arquivo(s) movido(s) para data/raw

ETAPA 1/3: EXTRAÃ‡ÃƒO
â¡ï¸ Etapa 1a: ConsolidaÃ§Ã£o de Arquivos de Despesas
   âœ… SIT 57884 (arquivo 57884.xlsx) - 150 linhas extraÃ­das
   ğŸ’¾ Total: 150 registros salvos em despesas_geral.csv
â¡ï¸ Etapa 1b: ExtraÃ§Ã£o de Resumos Financeiros
   âœ… SIT 57884 de 'resumo.csv'
   ğŸ’¾ Resumo termos: 1 registros salvos
   ğŸ’¾ Resumo rubricas: 5 registros salvos

ETAPA 2/3: TRANSFORMAÃ‡ÃƒO E VALIDAÃ‡ÃƒO
â¡ï¸ Etapa 2a: ComparaÃ§Ã£o Inteligente (Despesas)
ğŸ” Consultando banco de dados...
ğŸ“¦ 140 registros do banco carregados
   ğŸ“Š INSERT: 10 | UPDATE: 0 | IGNORE: 140
   ğŸ’¾ 10 registros salvos para upload
â¡ï¸ Etapa 2b: ValidaÃ§Ã£o de Termos e Rubricas
1ï¸âƒ£  Analisando Termos...
   âœ… Termos sincronizados.
2ï¸âƒ£  Analisando Rubricas...
   âœ… Rubricas sincronizadas.

=================== VALIDAÃ‡ÃƒO: Revise =================
ğŸ“Š DESPESAS A ATUALIZAR:
   â€¢ INSERT (novos): 10 registros
   â€¢ UPDATE (alterados): 0 registros
   â€¢ Total: 10 registros
   
   Amostra (primeiros registros):
      [INSERT] ID:SIT-001 | Termo:6373 | Valor:R$1500.00
      [INSERT] ID:SIT-002 | Termo:6373 | Valor:R$2000.00
      [INSERT] ID:SIT-003 | Termo:6373 | Valor:R$1200.50
      ... +7 registros

â“ Os dados acima estÃ£o CORRETOS? Digite 'SIM' para continuar: SIM

âœ… CONFIRMADO! Prosseguindo com a carga...

ETAPA 3/3: CARGA NO BANCO DE DADOS
â¡ï¸ Etapa 3a: Carga de Despesas (INSERT/UPDATE)
   ğŸš€ INSERT: 10 | UPDATE: 0
   âœ… Arquivo renomeado para .processado.csv
â¡ï¸ Etapa 3b: AtualizaÃ§Ã£o de Termos e Rubricas
   â„¹ï¸  Nada para atualizar (dados sincronizados)

======== âœ¨ PIPELINE CONCLUÃDO COM SUCESSO
â±ï¸  Tempo total: 12.45 segundos
======================================================
```

### Arquivos Criados:

```
data/processed/
â”œâ”€â”€ despesas_geral.csv                  â† Etapa 1
â”œâ”€â”€ despesas_upload.processado.csv      â† Etapa 3 (histÃ³rico)
â”œâ”€â”€ resumo_termos.csv                   â† Etapa 1
â”œâ”€â”€ resumo_rubricas.csv                 â† Etapa 1
â””â”€â”€ (update_*.csv - nÃ£o criados, dados sincronizados)

logs/
â””â”€â”€ MainPipeline_20260209_143022.log    â† Detalhes completos
```

### Banco de Dados:

```sql
-- 10 novos registros inseridos
SELECT COUNT(*) FROM despesas
-- Resultado: +10 (era 140, agora 150)
```

---

## ğŸ¯ Resumo em 1 Minuto

| O QuÃª | Como |
|-------|------|
| **Executar** | `python -m src.main` |
| **Confirmar dados** | Digite `SIM` quando pedido |
| **Ver logs** | Abra `logs/MainPipeline_*.log` |
| **Testar etapa 1** | `python -m src.extract.expenses` |
| **Testar etapa 2** | `python -m src.transform.transformer` |
| **Testar etapa 3** | `python -m src.load.loader` |
| **Com Docker** | `docker-compose up` |

---

**ğŸ“§ DÃºvidas?** Verificar logs ou executar com `--debug`

**ğŸš€ Pronto para produÃ§Ã£o!**
